<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog | Hongyi Du</title><link>https://Hongyi-Du.github.io/post/</link><atom:link href="https://Hongyi-Du.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Blog</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 21 May 2025 00:00:00 +0000</lastBuildDate><image><url>https://Hongyi-Du.github.io/media/icon_hu_645fa481986063ef.png</url><title>Blog</title><link>https://Hongyi-Du.github.io/post/</link></image><item><title>ModelingAgent submitted to EMNLP 2025 ðŸ“„</title><link>https://Hongyi-Du.github.io/post/emnlp2025-submitted/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://Hongyi-Du.github.io/post/emnlp2025-submitted/</guid><description>&lt;p>We have officially submitted our manuscript &amp;ldquo;ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges&amp;rdquo; to EMNLP 2025.&lt;/p>
&lt;h3 id="quick-links">Quick links&lt;/h3>
&lt;ul>
&lt;li>arXiv PDF â€” &lt;a href="https://arxiv.org/pdf/2505.15068" target="_blank" rel="noopener">2505.15068&lt;/a>&lt;/li>
&lt;li>Codebase â€” &lt;a href="https://github.com/qiancheng0/ModelingAgent" target="_blank" rel="noopener">https://github.com/qiancheng0/ModelingAgent&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The paper introduces ModelingBench, a real-world math-modeling benchmark, and ModelingAgent, a multi-agent framework that coordinates data retrieval, simulation, and self-refinement. &lt;em>Stay tuned for reviewer feedback and camera-ready updates!&lt;/em>&lt;/p></description></item><item><title>2 papers accepted to ACL 2025 ðŸŽ‰</title><link>https://Hongyi-Du.github.io/post/acl2025-accepted/</link><pubDate>Fri, 16 May 2025 00:00:00 +0000</pubDate><guid>https://Hongyi-Du.github.io/post/acl2025-accepted/</guid><description>&lt;p>Great news!
Both MultiAgentBench and EscapeBench have been officially accepted to ACL 2025 Main Conference (Vienna, July 2025).&lt;/p>
&lt;h3 id="highlights">Highlights&lt;/h3>
&lt;ul>
&lt;li>MultiAgentBench received uniformly positive reviews â€” one reviewer called it &amp;ldquo;interesting, forward-looking, and visionary,&amp;rdquo; noting it &amp;ldquo;fills a critical gap in current multi-agent evaluation.&amp;rdquo;&lt;/li>
&lt;li>We will submit the camera-ready version soon and keep updating the codebase &amp;amp; data to make the framework a SWE-bench equivalent for LLM multi-agent research.&lt;/li>
&lt;/ul>
&lt;p>Stay tuned â€” this post will be updated with links to the camera-ready PDF and dataset once they are available!&lt;/p></description></item></channel></rss>